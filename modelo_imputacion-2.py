import pandas as pd
import numpy as np
import glob
import os
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import statsmodels.formula.api as smf
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# --- CONFIGURACIÃ“N ---
RUTA_CARPETA = 'data/raw' 
aglomerados_a_analizar = [13, 32] # CÃ³rdoba y CABA
aÃ±os_modelo = range(2016, 2026)

# Variables clave del EPH
COL_INGRESO = 'P21'
COL_PONDERADOR = 'PONDII'  # ðŸ”‘ CORREGIDO: Ponderador de ingresos
COL_EDAD = 'CH06'
COL_SEXO = 'CH04'
COL_NIVEL_ED = 'NIVEL_ED'
COL_HORAS = 'PP3E_TOT'
COL_CAT_OCUP = 'CAT_OCUP'
COL_AGLOMERADO = 'AGLOMERADO'

print("="*80)
print(" ðŸ¤– DESARROLLO DE MODELO DE REGRESIÃ“N (IMPUTACIÃ“N DE INGRESOS)")
print("="*80)

# -------------------------------------------------------------------------
# 1. CARGA Y PREPARACIÃ“N DE DATOS
# -------------------------------------------------------------------------
list_df = []

print("Cargando bases de datos...")
for aÃ±o in aÃ±os_modelo:
    aÃ±o_sufijo = str(aÃ±o)[2:]
    search_patterns = [
        os.path.join(RUTA_CARPETA, f'*T?{aÃ±o_sufijo}.txt'), 
        os.path.join(RUTA_CARPETA, f'*4to.trim_{aÃ±o}.txt'), 
    ]
    files = sorted(list(set([f for p in search_patterns for f in glob.glob(p)])))
    
    if not files: continue
    
    try:
        dfs = [pd.read_csv(f, encoding='latin-1', sep=';', decimal=',', on_bad_lines='skip') for f in files]
        df_anual = pd.concat(dfs, ignore_index=True)
        df_anual.columns = df_anual.columns.str.upper().str.strip()
        df_anual['ANO_ENCUESTA'] = aÃ±o
        list_df.append(df_anual)
        print(f"  âœ… AÃ±o {aÃ±o}: {len(df_anual):,} registros")
    except Exception as e:
        print(f"  âš ï¸ Error en aÃ±o {aÃ±o}: {e}")
        continue

df_total = pd.concat(list_df, ignore_index=True)
print(f"\nðŸ“Š Total consolidado: {len(df_total):,} registros")

# --- PREPROCESAMIENTO Y LIMPIEZA DE TIPOS ---
cols_a_numerico = [COL_INGRESO, COL_EDAD, COL_HORAS, COL_NIVEL_ED, COL_CAT_OCUP, 
                   COL_AGLOMERADO, 'ESTADO', COL_PONDERADOR]

for col in cols_a_numerico:
    if col in df_total.columns:
        df_total[col] = pd.to_numeric(df_total[col], errors='coerce')

# ðŸ”‘ VALIDACIÃ“N: Calcular tasa de no respuesta ANTES de filtrar
total_ocupados = df_total[
    (df_total[COL_AGLOMERADO].isin(aglomerados_a_analizar)) &
    (df_total['ESTADO'] == 1) &
    (df_total[COL_EDAD] >= 14)
]

n_total = len(total_ocupados)
n_sin_ingreso = total_ocupados[
    (total_ocupados[COL_INGRESO].isna()) | (total_ocupados[COL_INGRESO] <= 0)
].shape[0]

tasa_no_respuesta = (n_sin_ingreso / n_total) * 100

print(f"\nðŸ“ˆ TASA DE NO RESPUESTA:")
print(f"   Total ocupados: {n_total:,}")
print(f"   Sin ingreso declarado: {n_sin_ingreso:,}")
print(f"   Tasa: {tasa_no_respuesta:.2f}%")

# Filtros para el modelo
df_model = df_total[
    (df_total[COL_AGLOMERADO].isin(aglomerados_a_analizar)) &
    (df_total['ESTADO'] == 1) & 
    (df_total[COL_EDAD] >= 14) &
    (df_total[COL_HORAS] > 0) &
    (df_total[COL_NIVEL_ED] < 9) & 
    (df_total[COL_CAT_OCUP].isin([1, 2, 3])) &  # ðŸ”‘ CORREGIDO: Excluir CAT_OCUP=4
    (df_total[COL_PONDERADOR] > 0)  # ðŸ”‘ AGREGADO: Validar ponderador
].copy()

print(f"ðŸ“Š Registros despuÃ©s de filtros: {len(df_model):,}")

# --- FEATURE ENGINEERING ---
df_model['EDAD_SQ'] = df_model[COL_EDAD] ** 2

# Filtrar casos CON ingreso para entrenamiento
df_train_valid = df_model[df_model[COL_INGRESO] > 0].copy()
df_train_valid['LOG_P21'] = np.log(df_train_valid[COL_INGRESO])

print(f"ðŸ“Š Casos vÃ¡lidos para entrenamiento: {len(df_train_valid):,}")

# -------------------------------------------------------------------------
# 2. ENTRENAMIENTO DEL MODELO
# -------------------------------------------------------------------------

# ðŸ”‘ CORREGIDO: DivisiÃ³n con estratificaciÃ³n por aglomerado
X_train, X_test = train_test_split(
    df_train_valid, 
    test_size=0.2, 
    random_state=42,
    stratify=df_train_valid[COL_AGLOMERADO]  # ðŸ”‘ AGREGADO
)

print(f"\nðŸ“Š DivisiÃ³n Train/Test:")
print(f"   Train: {len(X_train):,} ({len(X_train)/len(df_train_valid)*100:.1f}%)")
print(f"   Test:  {len(X_test):,} ({len(X_test)/len(df_train_valid)*100:.1f}%)")

# FÃ³rmula del modelo
formula = (
    "LOG_P21 ~ "
    "CH06 + EDAD_SQ + "
    "C(CH04) + "
    "C(NIVEL_ED) + "
    "np.log(PP3E_TOT) + "
    "C(CAT_OCUP) + "
    "C(AGLOMERADO) + "
    "C(ANO_ENCUESTA)"
)

print("\nðŸ”§ Entrenando modelo WLS...")
model = smf.wls(formula, data=X_train, weights=X_train[COL_PONDERADOR]).fit()

# -------------------------------------------------------------------------
# 3. EVALUACIÃ“N COMPLETA
# -------------------------------------------------------------------------

# ðŸ”‘ AGREGADO: EvaluaciÃ³n en TRAIN y TEST
pred_train_log = model.predict(X_train)
pred_test_log = model.predict(X_test)

pred_train_nivel = np.exp(pred_train_log)
pred_test_nivel = np.exp(pred_test_log)

y_train = X_train[COL_INGRESO]
y_test = X_test[COL_INGRESO]

# MÃ©tricas
r2_train = r2_score(np.log(y_train), pred_train_log)
r2_test = r2_score(np.log(y_test), pred_test_log)
rmse_train = np.sqrt(mean_squared_error(y_train, pred_train_nivel))
rmse_test = np.sqrt(mean_squared_error(y_test, pred_test_nivel))

# ðŸ”‘ AGREGADO: RÂ² Ajustado
n_train = len(X_train)
n_params = len(model.params)
r2_adj_train = 1 - (1 - r2_train) * (n_train - 1) / (n_train - n_params - 1)

print("\n" + "="*80)
print("ðŸ“Š EVALUACIÃ“N DEL MODELO")
print("="*80)
print(f"{'MÃ©trica':<30} {'Train':>15} {'Test':>15}")
print("-"*80)
print(f"{'RÂ² (Varianza explicada)':<30} {r2_train:>15.4f} {r2_test:>15.4f}")
print(f"{'RÂ² Ajustado':<30} {r2_adj_train:>15.4f} {'N/A':>15}")
print(f"{'RMSE (Error en $)':<30} ${rmse_train:>14,.0f} ${rmse_test:>14,.0f}")
print("="*80)

# ðŸ”‘ AGREGADO: DiagnÃ³stico de sobreajuste
if r2_test < r2_train - 0.1:
    print("âš ï¸  ADVERTENCIA: Posible sobreajuste (RÂ² test << RÂ² train)")
else:
    print("âœ… Modelo generaliza bien (sin sobreajuste significativo)")

# --- INTERPRETACIÃ“N DE COEFICIENTES (COMPLETA) ---
print("\n" + "="*80)
print("ðŸ“ COEFICIENTES DEL MODELO (Variables Significativas)")
print("="*80)

# Extraer coeficientes con p-value < 0.05
coef_df = pd.DataFrame({
    'Variable': model.params.index,
    'Coeficiente': model.params.values,
    'p-value': model.pvalues.values,
    'Significativo': model.pvalues.values < 0.05
})

coef_df['Efecto_%'] = (np.exp(coef_df['Coeficiente']) - 1) * 100

# Mostrar solo variables significativas
coef_signif = coef_df[coef_df['Significativo']].sort_values('p-value')

print(coef_signif[['Variable', 'Efecto_%', 'p-value']].to_string(index=False))
print("="*80)

# Interpretaciones clave
print("\nðŸ’¡ INTERPRETACIONES CLAVE:")
print("-"*80)

# Sexo
if 'C(CH04)[T.2]' in model.params.index:
    efecto_mujer = (np.exp(model.params['C(CH04)[T.2]']) - 1) * 100
    print(f"â€¢ Brecha de gÃ©nero (Mujer vs VarÃ³n): {efecto_mujer:+.1f}%")

# EducaciÃ³n
if 'C(NIVEL_ED)[T.6]' in model.params.index:
    efecto_univ = (np.exp(model.params['C(NIVEL_ED)[T.6]']) - 1) * 100
    print(f"â€¢ Universitario completo (vs Primaria incompleta): {efecto_univ:+.1f}%")

# Horas
if 'np.log(PP3E_TOT)' in model.params.index:
    elasticidad = model.params['np.log(PP3E_TOT)']
    print(f"â€¢ Elasticidad horas trabajadas: {elasticidad:.3f}")
    print(f"  (10% mÃ¡s horas â†’ {elasticidad*10:.1f}% mÃ¡s ingreso)")

# Aglomerado
if 'C(AGLOMERADO)[T.32]' in model.params.index:
    efecto_caba = (np.exp(model.params['C(AGLOMERADO)[T.32]']) - 1) * 100
    print(f"â€¢ Prima CABA vs CÃ³rdoba: {efecto_caba:+.1f}%")

# CategorÃ­a ocupacional
if 'C(CAT_OCUP)[T.3]' in model.params.index:
    efecto_cuentap = (np.exp(model.params['C(CAT_OCUP)[T.3]']) - 1) * 100
    print(f"â€¢ Cuenta propia vs PatrÃ³n: {efecto_cuentap:+.1f}%")

print("-"*80)

# --- GRÃFICO 1: VALORES PREDICHOS VS REALES ---
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Train
axes[0].scatter(pred_train_log, np.log(y_train), alpha=0.1, color='blue', s=1)
axes[0].plot([8, 15], [8, 15], 'r--', lw=2)
axes[0].set_xlabel("Log Ingreso Predicho")
axes[0].set_ylabel("Log Ingreso Real")
axes[0].set_title(f"Train Set (RÂ²={r2_train:.3f})")
axes[0].grid(True, alpha=0.3)

# Test
axes[1].scatter(pred_test_log, np.log(y_test), alpha=0.2, color='green', s=1)
axes[1].plot([8, 15], [8, 15], 'r--', lw=2)
axes[1].set_xlabel("Log Ingreso Predicho")
axes[1].set_ylabel("Log Ingreso Real")
axes[1].set_title(f"Test Set (RÂ²={r2_test:.3f})")
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('modelo_prediccion_vs_real-2.png', dpi=150)
plt.close()
print("\nâœ… GrÃ¡fico 'modelo_prediccion_vs_real-2.png' generado.")

# --- GRÃFICO 2: RESIDUOS ---
residuos_train = model.resid
residuos_test = np.log(y_test) - pred_test_log

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

axes[0].hist(residuos_train, bins=50, color='blue', alpha=0.7, edgecolor='black')
axes[0].set_title("DistribuciÃ³n de Residuos - Train")
axes[0].set_xlabel("Error (Log)")
axes[0].set_ylabel("Frecuencia")
axes[0].grid(True, alpha=0.3)

axes[1].hist(residuos_test, bins=50, color='green', alpha=0.7, edgecolor='black')
axes[1].set_title("DistribuciÃ³n de Residuos - Test")
axes[1].set_xlabel("Error (Log)")
axes[1].set_ylabel("Frecuencia")
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('modelo_residuos-2.png', dpi=150)
plt.close()
print("âœ… GrÃ¡fico 'modelo_residuos-2.png' generado.")

# -------------------------------------------------------------------------
# 4. IMPUTACIÃ“N
# -------------------------------------------------------------------------

df_no_respondentes = df_model[
    ((df_model[COL_INGRESO].isna()) | (df_model[COL_INGRESO] <= 0))
].copy()

df_no_respondentes['EDAD_SQ'] = df_no_respondentes[COL_EDAD] ** 2

if not df_no_respondentes.empty:
    print(f"\nðŸ”§ Imputando ingresos para {len(df_no_respondentes):,} casos...")
    print(f"   ({(len(df_no_respondentes)/n_total)*100:.2f}% del total de ocupados)")
    
    pred_imputacion_log = model.predict(df_no_respondentes)
    df_no_respondentes['P21_IMPUTADO'] = np.exp(pred_imputacion_log)
    
    # EstadÃ­sticas de imputaciÃ³n
    print(f"\nðŸ“Š ESTADÃSTICAS DE VALORES IMPUTADOS:")
    print(f"   Media:   ${df_no_respondentes['P21_IMPUTADO'].mean():,.0f}")
    print(f"   Mediana: ${df_no_respondentes['P21_IMPUTADO'].median():,.0f}")
    print(f"   Min:     ${df_no_respondentes['P21_IMPUTADO'].min():,.0f}")
    print(f"   Max:     ${df_no_respondentes['P21_IMPUTADO'].max():,.0f}")
    
    # Guardar muestra
    cols_export = ['ANO_ENCUESTA', 'AGLOMERADO', 'CH04', 'NIVEL_ED', 
                   'PP3E_TOT', 'CAT_OCUP', 'P21_IMPUTADO']
    df_export = df_no_respondentes[cols_export].copy()
    df_export.columns = ['AÃ±o', 'Aglomerado', 'Sexo', 'Nivel_Ed', 
                         'Horas', 'Cat_Ocup', 'Ingreso_Imputado']
    df_export.to_csv('ingresos_imputados-2.csv', index=False)
    print(f"âœ… Archivo 'ingresos_imputados-2.csv' generado ({len(df_export):,} casos)")
    
    # Resumen del modelo
    with open('modelo_resumen-2.txt', 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("RESUMEN COMPLETO DEL MODELO DE IMPUTACIÃ“N\n")
        f.write("="*80 + "\n\n")
        f.write(model.summary().as_text())
        f.write("\n\n" + "="*80 + "\n")
        f.write("INTERPRETACIÃ“N DE COEFICIENTES\n")
        f.write("="*80 + "\n")
        f.write(coef_signif[['Variable', 'Efecto_%', 'p-value']].to_string(index=False))
    
    print("âœ… Resumen estadÃ­stico guardado en 'modelo_resumen-2.txt'")

else:
    print("\nâš ï¸ No se encontraron casos para imputar")

print("\n" + "="*80)
print("âœ… PROCESO FINALIZADO CON Ã‰XITO")
print("="*80)